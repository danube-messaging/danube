# Danube Broker Configuration for Docker Compose with MinIO S3 Storage
# Optimized for cloud-ready deployment with AWS S3 compatibility

# Danube cluster name
cluster_name: "DANUBE_DOCKER_CLUSTER"

# Broker Services Configuration
broker:
  # Using 0.0.0.0 to bind to all interfaces within container
  host: "0.0.0.0"
  ports:
    # Client connections (producers/consumers)
    client: 6650
    # Admin API
    admin: 50051
    # Prometheus metrics exporter
    prometheus: 9040

# Metadata Store Configuration (etcd)
# Using container hostname for service discovery
meta_store:
  host: "etcd"
  port: 2379

# Namespaces to be created on boot
bootstrap_namespaces:
  - "default"
  - "examples"
  - "testing"

# Allow producers to auto-create topics when missing
auto_create_topics: true

# Security Configuration - Disabled for development
auth:
  mode: none # Options: none, tls, tlswithjwt

# Load Manager Configuration
load_manager:
  assignment_strategy: "balanced"
  load_report_interval_seconds: 30
  rebalancing:
    enabled: false
    aggressiveness: "balanced"
    check_interval_seconds: 300
    max_moves_per_hour: 10
    cooldown_seconds: 60
    min_brokers_for_rebalance: 2
    min_topic_age_seconds: 300
    blacklist_topics: []

# WAL and Cloud Storage Configuration
# Configured for MinIO S3-compatible storage
wal_cloud:
  wal:
    dir: "./danube-data/wal"
    file_name: "wal.log"
    cache_capacity: 1024
    # WAL file sync configuration, drive flush cadence and checkpoint frequency
    file_sync:
      interval_ms: 5000         # Default:Flush every 5s to reduce fsync pressure while keeping WAL checkpoints reasonably fresh
      max_batch_bytes: 10485760 # Default: 10 MiB writer batch
    # WAL file rotation configuration, balances file size and directory churn
    rotation:
      max_bytes: 536870912      # Default: 512 MiB WAL file size
      # max_hours: 24           # Optional time-based rotation (in hours)
    retention:
      time_minutes: 2880            # 48 hours (conservative production default)
      size_mb: 20480                # 20 GiB per topic
      check_interval_minutes: 5     # run every 5 minutes

  # Uploader configuration for background S3 uploads
  uploader:
    enabled: true
    interval_seconds: 60       # Default: Upload every 60 seconds for testing, Default is every 5 minutes
    root_prefix: "/danube-data"
    # Optional: maximum size per cloud object created in a single tick (in MiB). If unset, no cap.
    max_object_mb: 1024

  # Cloud storage backend - MinIO S3 configuration
  cloud:
    backend: "s3"
    root: "s3://danube-messages/cluster-data"  # S3 bucket and prefix
    region: "us-east-1"
    endpoint: "http://minio:9000"              # MinIO endpoint within Docker network
    access_key: "minioadmin"         # From environment variable
    secret_key: "minioadmin123"     # From environment variable
    anonymous: false
    virtual_host_style: false

  # Metadata configuration
  metadata:
    etcd_endpoint: "etcd:2379"
    in_memory: false

# Broker policies optimized for development and testing
policies:
  # Allow unlimited producers for testing
  max_producers_per_topic: 0

  # Allow unlimited subscriptions for testing
  max_subscriptions_per_topic: 0

  # Allow unlimited consumers for testing
  max_consumers_per_topic: 0

  # Allow unlimited consumers per subscription for testing
  max_consumers_per_subscription: 0

  # Allow high publish rate for performance testing
  max_publish_rate: 0

  # Allow high subscription dispatch rate for performance testing
  max_subscription_dispatch_rate: 0

  # Allow larger messages for testing (50 MB)
  max_message_size: 52428800
